Capstone Part 3: Getting Started (Hands-On)
Tasks 
Build a draft version of an API with train, predict, and logfile endpoints.

Using Docker, bundle your API, model, and unit tests.

Using test-driven development iterate on your API in a way that anticipates scale, load, and drift.

Create a post-production analysis script that investigates the relationship between model performance and the business metric.

Articulate your summarized findings in a final report.

Getting started
There are three tasks in the pieces to the final part of the case study:

Ready your model for deployment.

Query your API with new data and test your monitoring tools.

Compare your results to the gold standard.

Note:  In reality your model would re-train itself at some cadence (e.g. nightly or weekly). If your systems is capable of this you should demonstrate this capacity as part of the deliverable. This is not a requirement of the model for this assignment, but it is an important aspect of model deployment to keep in mind.

You will need to access the following link to download the files for completing this assignment prior to continuing. Please refer to Part 3 of the Readme for additional information/instructions:

https://github.com/aavail/ai-workflow-capstone