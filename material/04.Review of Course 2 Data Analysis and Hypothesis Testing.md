Review of Course 2: Data Analysis and Hypothesis Testing
Data Analysis
Exploratory Data Analysis
The main goals of EDA are:
Provide summary level insight into a data set

Uncover underlying patterns and structure in the data

Identify outliers, missing data and class balance issues

Carry out quality control checks

The principal steps in the process of EDA are:
Summarize the data - Generally done using dataframes in R or Python

Tell the Story - Summarize the details of what connects the dataset to the business opportunity

Deal with missing data - Identify the strategy for dealing with missing data

Investigate - Using data visualization and hypothesis testing delve into the relationship between the dataset and the business opportunity

Communicate - Communicate the findings from the above steps

Data visualization
Jupyter notebooks in combination with pandas and simple plots are the basis for modern EDA when using Python as a principal language

Advantages of Jupyter notebooks:
They are portable: then can be used locally on private servers, public cloud, and as part of IBM Watson Studio

They work with 
dozens of languages

They mix markdown with executable code in a way that works naturally with storytelling and investigation

matplotlib itself and its numerous derivative works like seaborn are the core of the Python data visualization landscape

pandas and specifically the dataframe class works naturally with Jupyter, matplotlib and downstream modeling frameworks like sklearn

EDA and Data Visualization best practices
The majority of code for any data science project should be contained within text files. This is a software engineering best practice that ensures re-usability, allows for unit testing and works naturally with version control. >In Python the text files can be executable scripts, modules, a full Python package or some combination of these.

Keep a record of plots and visualization code that you create. It is difficult to remember all of the details of how visualizations were created. Extracting the visualization code to a specific place will ensure that similar plots for future projects will be quick to create.

Use you plots as a quality assurance tool. Given what you know about the data it can be useful to make an educated guess before you execute the cell or run the script. This habit is surprisingly useful for quality assurance of both data and code.

Missing values
Dealing with missing data sits at the intersection of EDA and data ingestion in the AI enterprise workflow

Ignoring missing data may have unintended consequences in terms of model performance that may not be easy to detect

Removing either complete rows or columns in a feature matrix that contain missing values is called complete case analysis

Complete case analysis, although commonly used, can lead to undesirable results—the extent to which depends on the category of missingness

The categories of missingness are:
Missing completely at random or MCAR

Missing at random or MAR

Missing not at random or MNAR

The best case scenario is that the data are MCAR. It should be noted that imputing values under the other two types of missingness can result in an increase in bias.

In statistics the process of replacing missing data with substituted values is known as imputation.

It is a common practice to perform multiple imputations.

The practice of imputing missing values introduces uncertainty into the results of a data science project.

One way to deal with that additional uncertainty is to try a range of different values for imputation and measure how the results vary between each set of imputations. This technique is known as multiple imputation.

CASE STUDY: Data visualization
It can be easy to get lost in the details of the findings when communicating the finding from EDA to business stakeholders. Project planning and milestones are important so remember to talk about what you:

have done

are doing

and plan to do

Remember that deliverables are generally a presentation or a report and they should use a portable format (e.g. PDF or HTML)

Deliverables should should be concise and clear. Appendices are useful as supplemental materials to a deliverable and they help keep them free of unnecessary items.

Visual summaries are a key component of EDA deliverables

There is no single right way to communicate EDA, but a minimum bar is that the data summaries, key findings, investigative process, conclusions are made clear.


Data Investigation
TUTORIAL: IBM Watson Dashboard
With the analytics dashboard, you can
build sophisticated visualizations of your analytics results

communicate the insights that you’ve discovered in your data on the dashboard

share the dashboard with others

The visualizations can tell the story of an investigative process or they can be made to summarize and communicate data in a way that is difficult to do with simple plots.

Hypothesis Testing
Statistical inference and hypothesis testing can be used together to carry out investigations into the data

When carrying out a hypothesis test, the central question, null hypothesis and alternative hypothesis should be stated before the data are collected

Simulation based hypothesis testing like permutation tests provide a flexible alternative to more classical approaches

The bootstrap can be used to quantify the uncertainty around a parameter estimate and the two combined can be used as an investigative tool

Bayesian methods bring to the table a number of way to think differently about hypothesis testing. They generally require more time to implement, but the quantification of uncertainty can be useful when making important business decisions.

The t-test is a simple way to care out 1 or 2 sample hypothesis tests.

There are a number of variants on the t-test, but the unequal variances t-test is commonly used.

The t-test and ANOVA (more than two groups) test whether group means have differences between each other

CASE STUDY: Multiple comparisons
p-values themselves are not a source of ground truth, but they are nonetheless quite useful if used appropriately.

There are a number of ways hack your way to significant results using p-values

Running more than one hypothesis test, on the same data, results in the multiple comparisons problem.

Multiple comparisons are an issue because there is an expected false positive rate for running one test, and if we run multiple tests say using different combinations of features this expected rate should be higher.

The Bonferroni correction is commonly used to mitigate the multiple comparisons problem, but it is generally too conservative for large data sets.

A number of other methods are available including the Benjamini/Hochberg correction that is based on the false discovery rate.

Permutation experiments are offer an additional method to correct for multiple comparisons that require fewer assumptions.